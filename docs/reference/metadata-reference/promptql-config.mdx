---
sidebar_position: 17
sidebar_label: PromptQL Configuration
description:
  "Begin executing business logic directly from your GraphQL API using Hasura Data Domain Specification commands.
  Connect to REST endpoints, custom servers or serverless functions and better manage your back-end functions."
keywords:
  - hasura commands
  - hasura dds
  - graphql api
  - business logic
  - data connector
  - rest endpoint
  - custom server
  - serverless function
  - graphql instruction
  - command configuration
toc_max_heading_level: 4
---

# PromptQL Configuration

## Introduction

## How commands work

## Metadata structure


### PromptQlConfigV2 {#promptqlconfigv2-promptqlconfigv2}

Definition of the configuration of PromptQL, v2

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `kind` | `PromptQlConfig` | true |  |
| `version` | `v2` | true |  |
| `definition` | [PromptQlConfigV2](#promptqlconfigv2-promptqlconfigv2) | true | Definition of the configuration of PromptQL for the project |



#### PromptQlConfigV2 {#promptqlconfigv2-promptqlconfigv2}

Definition of the configuration of PromptQL for the project

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `systemInstructions` | string / null | false | Custom system instructions provided to every PromptQL thread that allows tailoring of behavior to match to the project's specific needs. |
| `llm` | [LlmConfig](#promptqlconfigv2-llmconfig) | true | Configuration of the LLM to be used for PromptQL |
| `aiPrimitivesLlm` | [LlmConfig](#promptqlconfigv2-llmconfig) / null | false | Configuration of the LLM to be used for AI primitives, such as classification, summarization etc |
| `featureFlags` | [undefined](#promptqlconfigv2-undefined) / null | false | Feature flags to be used for PromptQL |



#### undefined {#promptqlconfigv2-undefined}

Feature flags to be used for PromptQL

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `<customKey>` |  | false |  |



#### LlmConfig {#promptqlconfigv2-llmconfig}

Configuration of the LLM to be used for PromptQL


**One of the following values:**

| Value | Description |
|-----|-----|
| [HasuraLlmConfig](#promptqlconfigv2-hasurallmconfig) | Configuration settings for the Hasura-configured LLM |
| [OpenAiLlmConfig](#promptqlconfigv2-openaillmconfig) | Configuration settings for an OpenAI LLM |
| [AnthropicLlmConfig](#promptqlconfigv2-anthropicllmconfig) | Configuration settings for an Anthropic LLM |
| [AzureLlmConfig](#promptqlconfigv2-azurellmconfig) | Configuration settings for an Azure-provided LLM |
| [GeminiLlmConfig](#promptqlconfigv2-geminillmconfig) | Configuration settings for a Gemini LLM |
| [BedrockLlmConfig](#promptqlconfigv2-bedrockllmconfig) | Configuration settings for an AWS Bedrock-provided LLM |



#### BedrockLlmConfig {#promptqlconfigv2-bedrockllmconfig}

Configuration settings for an AWS Bedrock-provided LLM

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `provider` | `bedrock` | true |  |
| `modelId` | string | true | The specific AWS Bedrock model to use. |
| `regionName` | string | true | The specific AWS Bedrock region to use. |
| `awsAccessKeyId` | [EnvironmentValue](#promptqlconfigv2-environmentvalue) | true | The AWS access key ID to use for the AWS Bedrock API |
| `awsSecretAccessKey` | [EnvironmentValue](#promptqlconfigv2-environmentvalue) | true | The AWS secret access key to use for the AWS Bedrock API |



#### GeminiLlmConfig {#promptqlconfigv2-geminillmconfig}

Configuration settings for a Gemini LLM

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `provider` | `gemini` | true |  |
| `model` | string / null | false | The specific Gemini model to use. If not specified, the default model will be used. |
| `apiKey` | [EnvironmentValue](#promptqlconfigv2-environmentvalue) | true | The API key to use for the Gemini API |



#### AzureLlmConfig {#promptqlconfigv2-azurellmconfig}

Configuration settings for an Azure-provided LLM

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `provider` | `azure` | true |  |
| `apiVersion` | string / null | false | The specific Azure API version to use. If not specified, the default version will be used. |
| `model` | string / null | false | The specific Azure model to use. If not specified, the default model will be used. |
| `endpoint` | string | true | The endpoint to use for the Azure LLM API |
| `apiKey` | [EnvironmentValue](#promptqlconfigv2-environmentvalue) | true | The API key to use for the Azure API |



#### AnthropicLlmConfig {#promptqlconfigv2-anthropicllmconfig}

Configuration settings for an Anthropic LLM

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `provider` | `anthropic` | true |  |
| `model` | string / null | false | The specific Anthropic model to use. If not specified, the default model will be used. |
| `baseUrl` | string / null | false | The base URL to use for the Anthropic API. If not specified, the default URL will be used. |
| `apiKey` | [EnvironmentValue](#promptqlconfigv2-environmentvalue) | true | The API key to use for the Anthropic API |



#### OpenAiLlmConfig {#promptqlconfigv2-openaillmconfig}

Configuration settings for an OpenAI LLM

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `provider` | `openai` | true |  |
| `model` | string / null | false | The specific OpenAI model to use. If not specified, the default model will be used. |
| `baseUrl` | string / null | false | The base URL to use for the OpenAI API. If not specified, the default URL will be used. |
| `apiKey` | [EnvironmentValue](#promptqlconfigv2-environmentvalue) | true | The API key to use for the OpenAI API |



#### EnvironmentValue {#promptqlconfigv2-environmentvalue}

Either a literal string or a reference to a Hasura secret


**Must have exactly one of the following fields:**

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `value` | string | false |  |
| `valueFromEnv` | string | false |  |



#### HasuraLlmConfig {#promptqlconfigv2-hasurallmconfig}

Configuration settings for the Hasura-configured LLM

| Key | Value | Required | Description |
|-----|-----|-----|-----|
| `provider` | `hasura` | true |  |
